{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea058c7",
   "metadata": {},
   "source": [
    "# 10.3.3 Scrape Mars Data: The News"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0a8b2d7",
   "metadata": {},
   "source": [
    "https://courses.bootcampspot.com/courses/1225/pages/10-dot-3-3-scrape-mars-data-the-news?module_item_id=498538"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d80c458c",
   "metadata": {},
   "source": [
    "Many websites don't want automated browsers visiting their sites and snagging data. \n",
    "If there are too many visits, the server hosting the site could get overloaded and shut down. \n",
    "Administrators can then ban the IP address of the person doing the scraping, \n",
    "making it more difficult to even manually visit the site to view data.\n",
    "\n",
    "IMPORTANT\n",
    "Terms of Service and Terms of Use bring up an ethical issue when gathering data. \n",
    "Many websites don't allow automated browsing and scraping—some of the scraping scripts out there are designed to gather data quickly, and the constant traffic can overload web servers and disable a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d95df9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c262f7cd",
   "metadata": {},
   "source": [
    "IMPORTANT\n",
    "Remember, set your executable path in the next cell, then set up the URL for scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58be6da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [C:\\Users\\micha\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00b95d6a",
   "metadata": {},
   "source": [
    "In the next cell assign the url and instruct the browser to visit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47a54898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa news site\n",
    "url = 'https://redplanetscience.com'\n",
    "browser.visit(url)\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6577feb",
   "metadata": {},
   "source": [
    "With browser.is_element_present_by_css('div.list_text', wait_time=1), \n",
    "we are accomplishing two things:\n",
    "\n",
    "One is that we're searching for elements with a specific combination of tag (div) and attribute (list_text). \n",
    "\n",
    "    As an example, ul.item_list would be found in HTML as <ul class=\"item_list\">.\n",
    "\n",
    "Secondly, we're also telling our browser to wait one second before searching for components. \n",
    "\n",
    "    The optional delay is useful because sometimes dynamic pages take a little while to load,\n",
    "    especially if they are image-heavy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a60ac2d3",
   "metadata": {},
   "source": [
    "In the next cell, set up the HTML parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e446c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "news_soup = soup(html, 'html.parser')\n",
    "slide_elem = news_soup.select_one('div.list_text')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b120acd",
   "metadata": {},
   "source": [
    "Notice how we've assigned slide_elem as the variable to look for the <div /> tag and its descendent (the other tags within the <div /> element)? \n",
    "\n",
    "    This is our parent element. \n",
    "    This means that this element holds all of the other elements within\n",
    "    it, and we'll reference it when we want to filter search results even further. \n",
    "    \n",
    "    The . is used for selecting classes, such as list_text, \n",
    "    so the code 'div.list_text' pinpoints the <div /> tag with the class of list_text. \n",
    "    CSS works from right to left, such as returning the last item on the list instead of the first. \n",
    "    \n",
    "        Because of this, when using select_one, \n",
    "        the first matching element returned will be a <li /> element with\n",
    "        a class of slide and all nested elements within it.\n",
    "\n",
    "The data that the client wants to collect from this particular website is the most recent news article along with its summary. \n",
    "\n",
    "Remember, the code for this will eventually be used in an application that will scrape live data with the click of a button—this site is dynamic and the articles will change frequently, which is why the client is removing the manual task of retrieving each new article."
   ]
  },
  {
   "cell_type": "raw",
   "id": "47fa593c",
   "metadata": {},
   "source": [
    "After opening the page in a new browser, right-click to inspect and activate your DevTools. \n",
    "\n",
    "Then search for the HTML components you'll use to identify the title and paragraph you want.\n",
    "\n",
    "Q: Which HTML attribute will we use to scrape the article’s title?\n",
    "A: class = “content_title”"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23b3fad6",
   "metadata": {},
   "source": [
    "We'll want to assign the title and summary text to variables we'll reference later. In the next empty cell, let's begin our scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "277ff387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_title\">Heat and Dust Help Launch Martian Water Into Space, Scientists Find</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_elem.find('div', class_='content_title')\n",
    "\n",
    "# Go ahead and run this cell. The output should be the HTML containing the content title and anything else nested inside of that <div />."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a18be39",
   "metadata": {},
   "source": [
    "In this line of code, we chained .find onto our previously assigned variable, slide_elem. \n",
    "\n",
    "When we do this, we're saying, \"This variable holds a ton of information, so look inside of that information to find this specific data.\" \n",
    "\n",
    "The data we're looking for is the content title, which we've specified by saying, \"The specific data is in a <div /> with a class of 'content_title'.\"\n",
    "\n",
    "\n",
    "\n",
    "The title is in that mix of HTML in our output—that's awesome! But we need to get just the text, and the extra HTML stuff isn't necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77b23587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heat and Dust Help Launch Martian Water Into Space, Scientists Find'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the parent element to find the first `a` tag and save it as `news_title`\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "news_title\n",
    "\n",
    "# We've added something new to our .find() method here: .get_text(). \n",
    "# When this new method is chained onto .find(), only the text of the element is returned. \n",
    "# The code above, for example, would return only the title of the news article and not any of the HTML tags or elements."
   ]
  },
  {
   "cell_type": "raw",
   "id": "23cc2ecf",
   "metadata": {},
   "source": [
    "# Q: Although the code block above is similar to the last, what are the differences?\n",
    "# A: We have created a new variable for the title, added the get_text() method, and we’re searching within the parent element for the title."
   ]
  },
  {
   "cell_type": "raw",
   "id": "27d6b2b7",
   "metadata": {},
   "source": [
    "(If you aren't seeing this exact title, that's fine, because the webpage has likely been updated since the screenshot was taken. If you're not seeing a title at all, then check to make sure that you have selected the correct tag and attribute (such as div and class) in your find() function.)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3574359c",
   "metadata": {},
   "source": [
    "\"NASA's Mars 2020 Rover Completes Its First Drive\" --We have the title we want, and that's a great start. \n",
    "\n",
    "Next we need to add the summary text. \n",
    "\n",
    "This next block of code will be very similar to our last one.\n",
    "\n",
    "    Before we can update our code, we'll need to use our DevTools to make sure we're scraping the\n",
    "    right tag and class. Use the DevTools selector tool and select the article summary (teaser), then\n",
    "    check to see which tag is highlighted.\n",
    "    \n",
    "    We know that \"article_teaser_body\" is the right class name, but when we search for it, there is\n",
    "    more than one result. What now?\n",
    "    \n",
    "    That's okay. There will be many matches because there are many articles, \n",
    "    each with a tag of <div/> and a class of article_teaser_body. \n",
    "    We want to pull the first one on the list, not a specific one, \n",
    "    so more than 10 results is fine. In this case, if our scraping code is too specific, \n",
    "    we'd pull only that article summary instead of the most recent.\n",
    "\n",
    "    Because new articles are added to the top of the list, and we only need the most recent one, our\n",
    "    search leads us to the first article. New news only, please!\n",
    "    \n",
    "IMPORTANT\n",
    "There are two methods used to find tags and attributes with BeautifulSoup:\n",
    "\n",
    "(1) .find() is used when we want only the first class and attribute we've specified.\n",
    "(2) .find_all() is used when we want to retrieve all of the tags and attributes.\n",
    "\n",
    "For example, if we were to use .find_all() instead of .find() when pulling the summary, we would retrieve all of the summaries on the page instead of just the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ed131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scientists using an instrument aboard NASA’s Mars Atmosphere and Volatile EvolutioN, or MAVEN, spacecraft have discovered that water vapor near the surface of the Red Planet is lofted higher into the atmosphere than anyone expected was possible. '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the parent element to find the paragraph text\n",
    "# (Output should only be the summary of the article.)\n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939eabcb",
   "metadata": {},
   "source": [
    "# 10.3.4 Scrape Mars Data: Featured Image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "063c2359",
   "metadata": {},
   "source": [
    "https://courses.bootcampspot.com/courses/1225/pages/10-dot-3-4-scrape-mars-data-featured-image?module_item_id=498545"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d337506",
   "metadata": {},
   "source": [
    "The client's next step scraping code will be to gather the featured images from the Jet Propulsion Laboratory's Space Images webpage. \n",
    "https://spaceimages-mars.com/\n",
    "\n",
    "    Use markdown to separate the article scraping from the image scraping.\n",
    "\n",
    "    In the next empty cell, type ### Featured Images and change the \n",
    "    format of the code cell to \"Markdown.\"\n",
    "\n",
    "    You can access the cell formatting feature by using a drop-down menu at the top of the notebook.\n",
    "    It's currently set to \"Code,\" so click the down arrow to toggle the drop-down menu and select\n",
    "    \"Markdown\" instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb019ae8",
   "metadata": {},
   "source": [
    "### Featured Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10aeeb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ffc1acb",
   "metadata": {},
   "source": [
    "Run this code to make sure it's working correctly. \n",
    "A new automated browser should open to the featured images webpage."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd99952e",
   "metadata": {},
   "source": [
    "Next, we want to click the \"Full Image\" button. \n",
    "This button will direct our browser to an image slideshow. \n",
    "Let's take a look at the button's HTML tags and attributes with the DevTools.\n",
    "\n",
    "    <button class=\"btn btn-outline-light\"> FULL IMAGE</button>\n",
    "\n",
    "    This is a fairly straightforward HTML tag:\n",
    "    the <button> element has two classes (btn and btn-outline-light) and a string reading \"FULL\n",
    "    IMAGE\". \n",
    "    \n",
    "    First, let's use the dev tools to search for all the button elements.\n",
    "    \n",
    "    Since there are only three buttons, and we want to click the full-size image button, \n",
    "    we can go ahead and use the HTML tag in our code.\n",
    "\n",
    "    In the next cell, let's type the following:\n",
    "\n",
    "    # Find and click the full image button\n",
    "    full_image_elem = browser.find_by_tag('button')[1]\n",
    "    full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa03827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "full_image_elem.click()\n",
    "\n",
    "# Find and click the full image button\n",
    "# full_image_elem is a new variable to hold the scraping result.\n",
    "# browser.find_by_tag('button')[1] --> Splinter will \"click\" the image to view its full size.\n",
    "# full_image_elem.click() --> The browser finds an element by its tag."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4507accb",
   "metadata": {},
   "source": [
    "Notice the indexing chained at the end of the first line of code? \n",
    "\n",
    "    full_image_elem = browser.find_by_tag('button')[1]\n",
    "\n",
    "    With this, we've stipulated that we want our browser to click the second button.\n",
    "    \n",
    "        full_image_elem.click()\n",
    "\n",
    "Go ahead and run this code. \n",
    "The automated browser should automatically \"click\" the button and change the view to a slideshow of images, so we're on the right track. \n",
    "\n",
    "We need to click the More Info button to get to the next page. \n",
    "Let's look at the DevTools again to see what elements we can use for our scraping."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3996cfe7",
   "metadata": {},
   "source": [
    "With the new page loaded onto our automated browser, it needs to be parsed so we can continue and scrape the full-size image URL. In the next empty cell, type the following:\n",
    "\n",
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b03b2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "481cbb1e",
   "metadata": {},
   "source": [
    "Now we need to find the relative image URL. \n",
    "\n",
    "In our browser (make sure you're on the same page as the automated one), activate your DevTools again. \n",
    "\n",
    "    This time, let's find the image link for that image. This is a little more tricky. \n",
    "    Remember, the client wants to pull the most recently posted image for her web app.\n",
    "    \n",
    "    If she uses the image URL below, she'll only ever pull that specific image when using her app.\n",
    "    (Refer to module for image)\n",
    "    \n",
    "It's important to note that the value of the src will be different every time the page is updated, so we can't simply record the current value—we would only pull that image each time the code is executed, instead of the most recent one.\n",
    "\n",
    "    We'll use the image tag and class (<img />and fancybox-img) \n",
    "    to build the URL to the full-size image. \n",
    "    \n",
    "    # Find the relative image url\n",
    "    img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "    img_url_rel\n",
    "        \n",
    "        (1) An img tag is nested within this HTML, so we've included it.\n",
    "        (2) .get('src') pulls the link to the image.\n",
    "        \n",
    "            What we've done here is tell BeautifulSoup to look inside the <img /> tag for an image \n",
    "            with a class of fancybox-image. Basically we're saying, \"This is where the image we want\n",
    "            lives—use the link that's inside these tags.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0211359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars1.jpg'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the relative image url\n",
    "img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0f6281b",
   "metadata": {},
   "source": [
    "We were able to pull the link to the image by pointing BeautifulSoup to where the image will be, instead of grabbing the URL directly. \n",
    "\n",
    "This way, when JPL updates its image page, our code will still pull the most recent image.\n",
    "\n",
    "    image/featured/mars1.jpg\n",
    "\n",
    "    But if we copy and paste this link into a browser, it won't work. \n",
    "    This is because it's only a partial link, as the base URL isn't included. \n",
    "    If we look at our address bar in the webpage, we can see the entire URL up there already; \n",
    "    we just need to add the first portion to our app.\n",
    "    \n",
    "    Let's add the base URL to our code.\n",
    "    \n",
    "    # Use the base URL to create an absolute URL\n",
    "    img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "    img_url\n",
    "    \n",
    "        img_url is a variable that holds our f-string.\n",
    "        f'https://spaceimages-mars.com/ is an f-string, a type of string formatting used for print statements in Python.\n",
    "        {img_url_rel} --> The curly brackets hold a variable that will be inserted into the f-string when it's executed.\n",
    "        \n",
    "        We're using an f-string for this print statement because it's a cleaner way to create print statements; \n",
    "        they're also evaluated at run-time. \n",
    "        This means that it, and the variable it holds,\n",
    "            doesn't exist until the code is executed and the values are not constant. \n",
    "        This works well for our scraping app because the data we're scraping is live and will be updated frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f8f753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars1.jpg'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the base URL to create an absolute URL\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d570856",
   "metadata": {},
   "source": [
    "# 10.3.5 Scrape Mars Data: Mars Facts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f78a702",
   "metadata": {},
   "source": [
    "https://courses.bootcampspot.com/courses/1225/pages/10-dot-3-5-scrape-mars-data-mars-facts?module_item_id=498553"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9aa214b8",
   "metadata": {},
   "source": [
    "The client has chosen to collect her data from Mars Facts.\n",
    "https://galaxyfacts-mars.com/\n",
    "    \n",
    "So let's visit the webpage to look at what we'll be working with. \n",
    "The client already has a great photo and an article, so all she wants from this page is the table. \n",
    "Her plan is to display it as a table on her own web app, so keeping the current HTML table format is important.\n",
    "\n",
    "    Let's look at the webpage again, this time using our DevTools. All of the data we want is in a <table /> tag. \n",
    "    HTML codeused to create a table looks fairly complex, but it's really just breaking down and naming each component.\n",
    "    \n",
    "    <div class=\"sidebar\">\n",
    "\t\t\t\t<h5>MARS PLANET PROFILE</h5>\n",
    "\t\t\t\t<table class=\"table table-striped\">\n",
    "\t\t\t\t  <tbody>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Equatorial Diameter:</th>\n",
    "\t\t\t\t      <td>6,792 km</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Polar Diameter:</th>\n",
    "\t\t\t\t      <td>6,752 km</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Mass:</th>\n",
    "\t\t\t\t      <td>\t6.39 × 10^23 kg (0.11 Earths)</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Moons:</th>\n",
    "\t\t\t\t      <td>\t2 ( <span class=\"red\">Phobos </span> &amp; <span class=\"red\"> Deimos </span>)</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Orbit Distance:</th>\n",
    "\t\t\t\t      <td>\t227,943,824 km (1.38 AU)</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Orbit Period:</th>\n",
    "\t\t\t\t      <td>\t687 days (1.9 years)</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Surface Temperature:</th>\n",
    "\t\t\t\t      <td>\t-87 to -5 °C</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">First Record:</th>\n",
    "\t\t\t\t      <td>\t2nd millennium BC</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t    <tr>\n",
    "\t\t\t\t      <th scope=\"row\">Recorded By:</th>\n",
    "\t\t\t\t      <td>\tEgyptian astronomers</td>\n",
    "\t\t\t\t    </tr>\n",
    "\t\t\t\t  </tbody>\n",
    "\t\t\t\t</table>\n",
    "\n",
    "    Tables in HTML are basically made up of many smaller containers. \n",
    "    The main container is the <table /> tag. \n",
    "    \n",
    "    Inside the table is <tbody />, which is the body of the table—the headers, columns, and rows.\n",
    "\n",
    "    <tr /> is the tag for each table row. \n",
    "    Within that tag, the table data is stored in <td /> tags. \n",
    "    This is where the columns are established.\n",
    "    \n",
    "        Instead of scraping each row, or the data in each <td />, \n",
    "        we're going to scrape the entire table with Pandas' .read_html() function.\n",
    "\n",
    "        At the top of your Jupyter Notebook, add import pandas as pd to the dependencies and rerun the cell. \n",
    "        This way, we'll be able to use this new function without generating an error.\n",
    "\n",
    "\n",
    "\n",
    "        Back at the bottom of your notebook, in the next blank cell, let's set up our code.\n",
    "            \n",
    "            # Import Pandas dependency\n",
    "            import pandas as pd\n",
    "            df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "            df.columns=['description', 'Mars', 'Earth']\n",
    "            df.set_index('description', inplace=True)\n",
    "            df\n",
    "                \n",
    "                df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "                    With this line, we're creating a new DataFrame from the HTML table. \n",
    "                    The Pandas function read_html() specifically searches for and returns a list of tables found in the HTML. \n",
    "                    By specifying an index of 0, we're telling Pandas to pull only the first table it encounters, or the first \n",
    "                    item in the list. Then, it turns the table into a DataFrame.\n",
    "                    \n",
    "                df.columns=['description', 'Mars', 'Earth']\n",
    "                    Here, we assign columns to the new DataFrame for additional clarity.\n",
    "\n",
    "                df.set_index('description', inplace=True)\n",
    "                    By using the .set_index() function, we're turning the Description column into the DataFrame's index.\n",
    "                    inplace=True means that the updated index will remain in place, w\n",
    "                    ithout having to reassign the DataFrame to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7ff75d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars</th>\n",
       "      <th>Earth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter:</th>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from Sun:</th>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Year:</th>\n",
       "      <td>687 Earth days</td>\n",
       "      <td>365.24 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "      <td>-88 to 58°C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Mars            Earth\n",
       "description                                              \n",
       "Mars - Earth Comparison             Mars            Earth\n",
       "Diameter:                       6,779 km        12,742 km\n",
       "Mass:                    6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "Moons:                                 2                1\n",
       "Distance from Sun:        227,943,824 km   149,598,262 km\n",
       "Length of Year:           687 Earth days      365.24 days\n",
       "Temperature:                -87 to -5 °C      -88 to 58°C"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Pandas dependency\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "df.columns=['description', 'Mars', 'Earth']\n",
    "df.set_index('description', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ec99b33",
   "metadata": {},
   "source": [
    "This is exactly what the client is looking to add to her web application. \n",
    "How do we add the DataFrame to a web application? \n",
    "The client's web app is going to be an actual webpage. \n",
    "Our data is live—if the table is updated, then we want that change to appear in the client's app also.\n",
    "\n",
    "Thankfully, Pandas also has a way to easily convert our DataFrame back into HTML-ready code using the .to_html() function. \n",
    "Add this line to the next cell in your notebook and then run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e06d355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n      <th>Earth</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Mars - Earth Comparison</th>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_html()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c748436",
   "metadata": {},
   "source": [
    "The result is a slightly confusing-looking set of HTML code—it's a <table /> element with a lot of nested elements. \n",
    "\n",
    "This means success. \n",
    "\n",
    "After adding this exact block of code to the client's web app, the data it's storing will be presented in an easy-to-read tabular format."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6839a030",
   "metadata": {},
   "source": [
    "In the last empty cell of Jupyter Notebook, add browser.quit() and execute that cell to end the session.\n",
    "\n",
    "    IMPORTANT\n",
    "    Live sites are a great resource for fresh data, but the layout of the site may be updated or otherwise changed. \n",
    "    When this happens, there's a good chance your scraping code will break and need to be \n",
    "    reviewed and updated to be used again.\n",
    "\n",
    "    For example, an image may suddenly become embedded within an inaccessible block of code \n",
    "    because the developers switched to a new JavaScript library. It's not uncommon to revise code to \n",
    "    find workarounds or even look for a different, scraping-friendly site all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40f2ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c668ca",
   "metadata": {},
   "source": [
    "# 10.3.6 Export to Python (Instructions on how to export all of the code above as .py file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76150389",
   "metadata": {},
   "source": [
    "https://courses.bootcampspot.com/courses/1225/pages/10-dot-3-6-export-to-python?module_item_id=498560"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0601707e",
   "metadata": {},
   "source": [
    "The Jupyter ecosystem is an extremely versatile tool. \n",
    "We already know many of its great functions, such as the different libraries that work well with it and also how easy it is to troubleshoot code. \n",
    "\n",
    "Another feature is being able to download the notebook into different formats.\n",
    "\n",
    "There are several formats available, but we'll focus on one by downloading to a Python file.\n",
    "\n",
    "        While your notebook is open, navigate to the top of the page to the Files tab.\n",
    "\n",
    "        From here, scroll down to the \"Download as\" section of the drop-down menu.From here, \n",
    "        scroll down to the \"Download as\" section of the drop-down menu.\n",
    "        \n",
    "        Select \"Python (.py)\" from the next menu to download the code.Select \"Python (.py)\"\n",
    "        from the next menu to download the code.\n",
    "        \n",
    "If you get a warning about downloading this type of file, click \"Keep\" to continue the download. If you get a warning about downloading this type of file, click \"Keep\" to continue the download. \n",
    "\n",
    "        Navigate to your Downloads folder and open the new file. \n",
    "        A brief look at the first lines of code shows us that the code wasn't the only thing to be ported over. \n",
    "        The number of times each cell has been run is also there, for example.\n",
    "        Navigate to your Downloads folder and open the new scraping.py file\n",
    "        \n",
    "        Clean up the code by removing unnecessary blank spaces and comments.\n",
    "        \n",
    "        When you're done tidying up the code, make sure you save it in your working folder \n",
    "        with your notebook code as scraping.py. You can also test the script by running it through your terminal.\n",
    "\n",
    "\n",
    "\n",
    "The final scraping.py file should look like this:\n",
    "\n",
    "\n",
    "\n",
    "# Import Splinter, BeautifulSoup, and Pandas\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Visit the Mars news site\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)\n",
    "\n",
    "# Convert the browser html to a soup object and then quit the browser\n",
    "html = browser.html\n",
    "news_soup = soup(html, 'html.parser')\n",
    "\n",
    "slide_elem = news_soup.select_one('div.list_text')\n",
    "\n",
    "slide_elem.find('div', class_='content_title')\n",
    "\n",
    "# Use the parent element to find the first a tag and save it as `news_title`\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "news_title\n",
    "\n",
    "# Use the parent element to find the paragraph text\n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "news_p\n",
    "\n",
    "# ## JPL Space Images Featured Image\n",
    "\n",
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com'\n",
    "browser.visit(url)\n",
    "\n",
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "full_image_elem.click()\n",
    "\n",
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')\n",
    "\n",
    "# find the relative image url\n",
    "img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel\n",
    "\n",
    "# Use the base url to create an absolute url\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url\n",
    "\n",
    "# ## Mars Facts\n",
    "\n",
    "df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "df.head()\n",
    "\n",
    "df.columns=['Description', 'Mars', 'Earth']\n",
    "df.set_index('Description', inplace=True)\n",
    "df\n",
    "\n",
    "df.to_html()\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "\n",
    "\n",
    "        Although it was a little tedious to clean up the code, at least you didn't have to rewrite everything or copy and paste\n",
    "        the code cell by cell. Also, Jupyter Notebook can be converted to other file types as well, such as markdown and text,\n",
    "        so this is a really useful skill to have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
